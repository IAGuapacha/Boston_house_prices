{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wbepu01LHJoL"
   },
   "source": [
    "# Trabajo Preparacion, visualizacion de Datos y Machine learning con Python<a class=\"tocSkip\">\n",
    "## Ciencia de datos en Produccion <a class=\"tocSkip\">\n",
    "\n",
    "**Estudiante:** xxxxxxxxxx\n",
    "\n",
    "**ID:** xxxxxxxxxx\n",
    "\n",
    "**Email:** xxxxx\n",
    "\n",
    " \n",
    "**Ponga su nombre en el archivo de Jupyter Notebook \n",
    "Docente: [Jose R. Zapata](https://joserzapata.github.io)\n",
    "- https://joserzapata.github.io\n",
    "- https://twitter.com/joserzapata\n",
    "- https://www.linkedin.com/in/jose-ricardo-zapata-gonzalez/       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s_RCEnM3HJoL",
    "toc": true
   },
   "source": [
    "<h1>Contenido<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Definir-el-Problema-a-Resolver\" data-toc-modified-id=\"Definir-el-Problema-a-Resolver-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Definir el Problema a Resolver</a></span><ul class=\"toc-item\"><li><span><a href=\"#Describir-los-datos-de-entrada-y-salida\" data-toc-modified-id=\"Describir-los-datos-de-entrada-y-salida-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Describir los datos de entrada y salida</a></span></li></ul></li><li><span><a href=\"#Importar-Librerias\" data-toc-modified-id=\"Importar-Librerias-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Importar Librerias</a></span></li><li><span><a href=\"#Cargar-Datasets\" data-toc-modified-id=\"Cargar-Datasets-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Cargar Datasets</a></span></li><li><span><a href=\"#Descripcion--y-Limpieza-de-los-datos\" data-toc-modified-id=\"Descripcion--y-Limpieza-de-los-datos-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Descripcion  y Limpieza de los datos</a></span><ul class=\"toc-item\"><li><span><a href=\"#Identificacion-de-Variables\" data-toc-modified-id=\"Identificacion-de-Variables-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Identificacion de Variables</a></span></li><li><span><a href=\"#Analisis-General-Univariable-y-Bivariable\" data-toc-modified-id=\"Analisis-General-Univariable-y-Bivariable-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Analisis General Univariable y Bivariable</a></span></li><li><span><a href=\"#Eliminar-columnas-de-datos-Innecesarios\" data-toc-modified-id=\"Eliminar-columnas-de-datos-Innecesarios-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Eliminar columnas de datos Innecesarios</a></span></li><li><span><a href=\"#Remover-Datos-Duplicados-Exactos\" data-toc-modified-id=\"Remover-Datos-Duplicados-Exactos-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Remover Datos Duplicados Exactos</a></span></li><li><span><a href=\"#Procesamiento-de-Datos-Faltantes\" data-toc-modified-id=\"Procesamiento-de-Datos-Faltantes-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Procesamiento de Datos Faltantes</a></span><ul class=\"toc-item\"><li><span><a href=\"#Borrar-Filas\" data-toc-modified-id=\"Borrar-Filas-4.5.1\"><span class=\"toc-item-num\">4.5.1&nbsp;&nbsp;</span>Borrar Filas</a></span></li><li><span><a href=\"#Reemplazar-datos-faltantes-con-la-Media/-Moda/-Mediana-(Mean/-Mode/-Median-Imputation)\" data-toc-modified-id=\"Reemplazar-datos-faltantes-con-la-Media/-Moda/-Mediana-(Mean/-Mode/-Median-Imputation)-4.5.2\"><span class=\"toc-item-num\">4.5.2&nbsp;&nbsp;</span>Reemplazar datos faltantes con la Media/ Moda/ Mediana (Mean/ Mode/ Median Imputation)</a></span></li></ul></li><li><span><a href=\"#Remover-Datos-Duplicados-Exactos\" data-toc-modified-id=\"Remover-Datos-Duplicados-Exactos-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Remover Datos Duplicados Exactos</a></span></li><li><span><a href=\"#Analisis-Univariable\" data-toc-modified-id=\"Analisis-Univariable-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Analisis Univariable</a></span><ul class=\"toc-item\"><li><span><a href=\"#Variables-Numericas\" data-toc-modified-id=\"Variables-Numericas-4.7.1\"><span class=\"toc-item-num\">4.7.1&nbsp;&nbsp;</span>Variables Numericas</a></span></li><li><span><a href=\"#Variables-Categoricas\" data-toc-modified-id=\"Variables-Categoricas-4.7.2\"><span class=\"toc-item-num\">4.7.2&nbsp;&nbsp;</span>Variables Categoricas</a></span></li></ul></li><li><span><a href=\"#Analisis-Bivariable\" data-toc-modified-id=\"Analisis-Bivariable-4.8\"><span class=\"toc-item-num\">4.8&nbsp;&nbsp;</span>Analisis Bivariable</a></span><ul class=\"toc-item\"><li><span><a href=\"#Numericas-vs-Numericas\" data-toc-modified-id=\"Numericas-vs-Numericas-4.8.1\"><span class=\"toc-item-num\">4.8.1&nbsp;&nbsp;</span>Numericas vs Numericas</a></span></li><li><span><a href=\"#Categoricas-vs-Categoricas\" data-toc-modified-id=\"Categoricas-vs-Categoricas-4.8.2\"><span class=\"toc-item-num\">4.8.2&nbsp;&nbsp;</span>Categoricas vs Categoricas</a></span></li><li><span><a href=\"#Categoricas-vs-Numericas\" data-toc-modified-id=\"Categoricas-vs-Numericas-4.8.3\"><span class=\"toc-item-num\">4.8.3&nbsp;&nbsp;</span>Categoricas vs Numericas</a></span></li></ul></li><li><span><a href=\"#Procesamiento-de-Outliers\" data-toc-modified-id=\"Procesamiento-de-Outliers-4.9\"><span class=\"toc-item-num\">4.9&nbsp;&nbsp;</span>Procesamiento de Outliers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deteccion-de-Outliers-(Univariables-y-Bi-variables)\" data-toc-modified-id=\"Deteccion-de-Outliers-(Univariables-y-Bi-variables)-4.9.1\"><span class=\"toc-item-num\">4.9.1&nbsp;&nbsp;</span>Deteccion de Outliers (Univariables y Bi variables)</a></span></li><li><span><a href=\"#Remover-Outliers\" data-toc-modified-id=\"Remover-Outliers-4.9.2\"><span class=\"toc-item-num\">4.9.2&nbsp;&nbsp;</span>Remover Outliers</a></span></li></ul></li><li><span><a href=\"#Procesamiento-de-Outliers\" data-toc-modified-id=\"Procesamiento-de-Outliers-4.10\"><span class=\"toc-item-num\">4.10&nbsp;&nbsp;</span>Procesamiento de Outliers</a></span><ul class=\"toc-item\"><li><span><a href=\"#Deteccion-de-Outliers-(Univariables-y-Bi-variables)\" data-toc-modified-id=\"Deteccion-de-Outliers-(Univariables-y-Bi-variables)-4.10.1\"><span class=\"toc-item-num\">4.10.1&nbsp;&nbsp;</span>Deteccion de Outliers (Univariables y Bi variables)</a></span></li><li><span><a href=\"#Remover-Outliers\" data-toc-modified-id=\"Remover-Outliers-4.10.2\"><span class=\"toc-item-num\">4.10.2&nbsp;&nbsp;</span>Remover Outliers</a></span></li></ul></li><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-4.11\"><span class=\"toc-item-num\">4.11&nbsp;&nbsp;</span>Feature Engineering</a></span><ul class=\"toc-item\"><li><span><a href=\"#Transformacion-de-Variables\" data-toc-modified-id=\"Transformacion-de-Variables-4.11.1\"><span class=\"toc-item-num\">4.11.1&nbsp;&nbsp;</span>Transformacion de Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Normalizacion\" data-toc-modified-id=\"Normalizacion-4.11.1.1\"><span class=\"toc-item-num\">4.11.1.1&nbsp;&nbsp;</span>Normalizacion</a></span></li><li><span><a href=\"#Escalamiento\" data-toc-modified-id=\"Escalamiento-4.11.1.2\"><span class=\"toc-item-num\">4.11.1.2&nbsp;&nbsp;</span>Escalamiento</a></span></li><li><span><a href=\"#Logaritmica\" data-toc-modified-id=\"Logaritmica-4.11.1.3\"><span class=\"toc-item-num\">4.11.1.3&nbsp;&nbsp;</span>Logaritmica</a></span></li><li><span><a href=\"#raíz-cuadrada-/-cúbica\" data-toc-modified-id=\"raíz-cuadrada-/-cúbica-4.11.1.4\"><span class=\"toc-item-num\">4.11.1.4&nbsp;&nbsp;</span>raíz cuadrada / cúbica</a></span></li><li><span><a href=\"#Binning-,-Cambios-de-Numericas-a-Categoricas\" data-toc-modified-id=\"Binning-,-Cambios-de-Numericas-a-Categoricas-4.11.1.5\"><span class=\"toc-item-num\">4.11.1.5&nbsp;&nbsp;</span>Binning , Cambios de Numericas a Categoricas</a></span></li></ul></li></ul></li><li><span><a href=\"#Analisis-Univariable-y-Bivariable-Final\" data-toc-modified-id=\"Analisis-Univariable-y-Bivariable-Final-4.12\"><span class=\"toc-item-num\">4.12&nbsp;&nbsp;</span>Analisis Univariable y Bivariable Final</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creacion-de-Variables\" data-toc-modified-id=\"Creacion-de-Variables-4.12.1\"><span class=\"toc-item-num\">4.12.1&nbsp;&nbsp;</span>Creacion de Variables</a></span><ul class=\"toc-item\"><li><span><a href=\"#Crear-Variables-derivadas-de-Otras\" data-toc-modified-id=\"Crear-Variables-derivadas-de-Otras-4.12.1.1\"><span class=\"toc-item-num\">4.12.1.1&nbsp;&nbsp;</span>Crear Variables derivadas de Otras</a></span></li><li><span><a href=\"#Crear-Variables-de-Categorico-a-Numerico\" data-toc-modified-id=\"Crear-Variables-de-Categorico-a-Numerico-4.12.1.2\"><span class=\"toc-item-num\">4.12.1.2&nbsp;&nbsp;</span>Crear Variables de Categorico a Numerico</a></span></li></ul></li></ul></li><li><span><a href=\"#Reduccion-de-Dimensionalidad-y-Seleccion-de-Variables-(PCA)\" data-toc-modified-id=\"Reduccion-de-Dimensionalidad-y-Seleccion-de-Variables-(PCA)-4.13\"><span class=\"toc-item-num\">4.13&nbsp;&nbsp;</span>Reduccion de Dimensionalidad y Seleccion de Variables (PCA)</a></span></li><li><span><a href=\"#Balance-de-datos\" data-toc-modified-id=\"Balance-de-datos-4.14\"><span class=\"toc-item-num\">4.14&nbsp;&nbsp;</span>Balance de datos</a></span></li></ul></li><li><span><a href=\"#MODELAMIENTO-DE-LOS-DATOS-(MACHINE-LEARNING)\" data-toc-modified-id=\"MODELAMIENTO-DE-LOS-DATOS-(MACHINE-LEARNING)-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>MODELAMIENTO DE LOS DATOS (MACHINE LEARNING)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dividir-el-dataset-en-Training-set-y-Test-set\" data-toc-modified-id=\"Dividir-el-dataset-en-Training-set-y-Test-set-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Dividir el dataset en Training set y Test set</a></span></li></ul></li><li><span><a href=\"#Validacion-y-Evaluacion-Cruzada-(k-fold-Cross-Validation)\" data-toc-modified-id=\"Validacion-y-Evaluacion-Cruzada-(k-fold-Cross-Validation)-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Validacion y Evaluacion Cruzada (k-fold Cross Validation)</a></span></li><li><span><a href=\"#Optimizacion-de-Hiper-parametros-(Hyper-Parameter-optimization)\" data-toc-modified-id=\"Optimizacion-de-Hiper-parametros-(Hyper-Parameter-optimization)-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Optimizacion de Hiper parametros (Hyper Parameter optimization)</a></span></li><li><span><a href=\"#Evaluacion-final-del-modelo-con-el-Test-set\" data-toc-modified-id=\"Evaluacion-final-del-modelo-con-el-Test-set-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Evaluacion final del modelo con el Test set</a></span></li><li><span><a href=\"#Implementacion-del-Modelo-(Deploying)\" data-toc-modified-id=\"Implementacion-del-Modelo-(Deploying)-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Implementacion del Modelo (Deploying)</a></span></li><li><span><a href=\"#Comunicacion-de-Resultados-(Data-Story-Telling)\" data-toc-modified-id=\"Comunicacion-de-Resultados-(Data-Story-Telling)-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Comunicacion de Resultados (Data Story Telling)</a></span></li><li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Conclusiones</a></span></li><li><span><a href=\"#Ayudas-Y-Referencias\" data-toc-modified-id=\"Ayudas-Y-Referencias-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Ayudas Y Referencias</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo del Trabajo <a class=\"tocSkip\">\n",
    "El objetivo inicial del trabajo es utilizar Python para el procesamiento, descripcion  y visualización de datos, con el fin de dejar los datos preparados para ser usados con algoritmos de Machine Learning para Regresión o Clasificación como objetivo final del trabajo.\n",
    "\n",
    "El trabajo se realizara en Python usando un jupyter notebook o un Notebook de Google Collaboratory, llenando los campos de este archivo y subirlo a github.\n",
    "\n",
    "## Las actividades a realizar<a class=\"tocSkip\">\n",
    "    \n",
    "    \n",
    "1) Preparar los datos, hacer cada uno de los pasos solo si es necesario:\n",
    "      \n",
    "    - Poner los datos en sus tipos de datos correctos\n",
    "    - Remover los valores duplicados\n",
    "    - Procesar y Reemplazar los datos que faltan (Missing N.A values)\n",
    "    - Manejo de outliers\n",
    "    - Re-escalar las variables\n",
    "    - Normalizar\n",
    "    - Data Binning\n",
    "        - Conversión Numérico a categórico\n",
    "        - Conversión Categórico a Numérico\n",
    "\n",
    "2) Realizar una exploración estadística y con visualización de los datos\n",
    "    - Scatter plots\n",
    "    - Histogramas\n",
    "    - boxplot, o las gráficas que considere necesarias\n",
    "\n",
    "\n",
    "3) Entrene y Evalue modelos de Machine Learning según sea su problema, recuerde usar k-fold cross-validation para evitar over fitting, algunos algoritmos recomendados\n",
    "\n",
    "    (a) PREDICCIÓN:\n",
    "    \n",
    "            ▪ Regresión Lineal\n",
    "            ▪ Lasso\n",
    "            ▪ Ridge\n",
    "            ▪ Decision Tree regressor\n",
    "            ▪ Random Forest regressor\n",
    "            ▪ SVR\n",
    "            ▪ KNR\n",
    "            ▪ catboost regressor\n",
    "            \n",
    "    \n",
    "    \n",
    "    (b) CLASIFICACION\n",
    "      \n",
    "            ▪ Regresión Logística\n",
    "            ▪ LinearSVC\n",
    "            ▪ KernelSVC\n",
    "            ▪ Decision Tree clasifier\n",
    "            ▪ Random Forest classifier\n",
    "            ▪ K-NN\n",
    "            ▪ GaussianNB\n",
    "            ▪ catboost\n",
    "    \n",
    "**Nota: utilizar visualizaciones para comunicar los resultados obtenidos.**    \n",
    "            \n",
    "4) Realizar hyperparameter optimization  de los dos métodos que tengan mejor resultado en los pasos anteriores para mejorar el desempeño obtenido. (Tenga en cuenta, que realizar el hyperparameter tuning no garantiza una mejora significativa en el desempeño, pero es bueno intentarlo)\n",
    "    \n",
    "5) Realizar comentarios de cada paso que va realizando en el documento y finalmente también agregue **conclusiones** de:\n",
    "    \n",
    "    - los datos procesados\n",
    "    - la información que observa\n",
    "    - Comparación de la evaluación de los Métodos\n",
    "    - Cual fue el mejor modelo que obtuvo luego de la hiper parametrización\n",
    "    \n",
    "    \n",
    "*NOTA: No dude en contactarme para cualquier pregunta o inquietud :)\n",
    "\n",
    "## FORMATO DE ENTREGA  <a class=\"tocSkip\">\n",
    "\n",
    "EL jupyter notebook estara alojado en un repositorio de Github\n",
    "\n",
    "El código debe tener comentarios y explicaciones de la solución del trabajo.\n",
    "\n",
    "\n",
    "## EVALUACION <a class=\"tocSkip\">\n",
    "(33 % ) preparacion, descripcion y visualizacion de datos\n",
    "    \n",
    "(33 % ) Machine Learning, hiperparametrizacion y Conclusiones\n",
    "    \n",
    "\n",
    "|Porcentaje en la evaluación | Descripción| Nada | Incompleto | Completo |\n",
    "| :---: |:---: |:---: |:---: |:---: |\n",
    "| 11 % |**Preparación de los datos** <br> (datos nulos, outliers, duplicados, <br> corrección de formatos de tipos de datos) |\n",
    "|11 % | **Visualización de datos** <br> (Univarible y Bivariable) <br> Histogramas, boxplots, correlaciones, etc|\n",
    "|11 % | **Descripción y Análisis Estadístico de los datos** |\n",
    "|11 % | **Machine Learning** <br> Entrenar y evaluar todos los modelos propuestos |\n",
    "|11 % | **Hiper parametrizacion** <br> Hiperparametrizar 2 modelos y escoger el mejor modelo |   \n",
    "|11 % | **Resultados y Conclusiones** <br> analisis de los datos, conclusiones del modelos y los resultados obtenidos|\n",
    "\n",
    "\n",
    "Ejemplos y links de ayuda al final del documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XE2q_0ARHJoM"
   },
   "source": [
    "# Definir el Problema a Resolver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0fWGXusiHJoO"
   },
   "source": [
    "## Describir los datos de entrada y salida\n",
    "- Cantidad de Variables\n",
    "- Tipo de Variables\n",
    "- Significado de cada Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MjPWhesSHJoO"
   },
   "source": [
    "# Importar Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ksQYJRZTHJoP"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LM4dC7lBHJoT"
   },
   "source": [
    "# Cargar Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2C-zrtBHJoT"
   },
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(\"../data/raw/Precios_Casas_BostonDS.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descripcion General del Dataset\n",
    "- numero de filas y columnas\n",
    "- tipos de datos y si estan correctos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13440 entries, 0 to 13439\n",
      "Data columns (total 19 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  13440 non-null  int64 \n",
      " 1   index       13440 non-null  int64 \n",
      " 2   zn          12925 non-null  object\n",
      " 3   black       12895 non-null  object\n",
      " 4   rad         12895 non-null  object\n",
      " 5   indus       12850 non-null  object\n",
      " 6   ptratio     12980 non-null  object\n",
      " 7   medv        12675 non-null  object\n",
      " 8   lstat       12970 non-null  object\n",
      " 9   nbgde       12970 non-null  object\n",
      " 10  chas        13010 non-null  object\n",
      " 11  ftyrgv      13440 non-null  int64 \n",
      " 12  ID          12995 non-null  object\n",
      " 13  crim        12890 non-null  object\n",
      " 14  dis         12820 non-null  object\n",
      " 15  tax         12835 non-null  object\n",
      " 16  rm          12900 non-null  object\n",
      " 17  age         12890 non-null  object\n",
      " 18  nox         13000 non-null  object\n",
      "dtypes: int64(3), object(16)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de calidad de datos general\n",
    "- Filas con valores exactamente iguales (duplicados)\n",
    "- Columnas duplicadas\n",
    "- Columnas con valores constantes o sin informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        False\n",
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "         ...  \n",
       "13435    False\n",
       "13436    False\n",
       "13437    False\n",
       "13438    False\n",
       "13439    False\n",
       "Length: 13440, dtype: bool"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw.drop(['ftyrgv','Unnamed: 0'],axis= 1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividir el dataset en Training set y Test set\n",
    "\n",
    "Este paso debe ser al inicio de los proyectos,  Se deben realizar todas las transformaciones, preparación de datos y limpieza de los datos, en el train set y en la evaluacion se deben aplicarl al test set y a los datos nuevos que lleguen al sistema. Esta division inicial se hace para evitar data leakage de los datos de test a los datos de train, por ejemplo en las imputaciones.\n",
    "\n",
    "Por este motivo se realizara en esta parte.\n",
    "\n",
    "Division de los datos de entrenamiento (Train set) y de Evaluacion (test - set), las divisiones utilizadas son\n",
    "\n",
    "- 80% (train) , 20%(test)\n",
    "- 70% (train) , 30%(test)\n",
    "\n",
    "El **Train set** se hace para seleccion de Modelos y el **Test-set** solamente para la evaluacion Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12836/2006888277.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_raw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'medv'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m123\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\guapa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2195\u001b[0m                      random_state=random_state)\n\u001b[0;32m   2196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2197\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2199\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n",
      "\u001b[1;32mc:\\Users\\guapa\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1791\u001b[0m         \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m         \"\"\"\n\u001b[1;32m-> 1793\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1794\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\guapa\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\guapa\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    722\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\guapa\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input contains NaN\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN"
     ]
    }
   ],
   "source": [
    "x = data_raw.drop('medv',axis=1)\n",
    "y = data_raw['medv']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2,random_state =123, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       index                   zn   black                  rad  \\\n",
      "90       189                 90.0  395.52                  1.0   \n",
      "6472     202                xxxxx     NaN                  7.0   \n",
      "7818     309  gdhg7u8whui 784gryb  395.33                 24.0   \n",
      "12894    278                  0.0   81.33                 24.0   \n",
      "1948      93                  0.0  394.08                  4.0   \n",
      "...      ...                  ...     ...                  ...   \n",
      "2210       3     88876599956788.0   396.9                  3.0   \n",
      "6100      57                  0.0   396.9                  3.0   \n",
      "1480     410                  0.0  378.25                  4.0   \n",
      "2874      42     88876599956788.0  393.24                  3.0   \n",
      "9717     345                  0.0   396.9  gdhg7u8whui 784gryb   \n",
      "\n",
      "                     indus ptratio                 medv                lstat  \\\n",
      "90                    1.21    13.6                 50.0                 3.16   \n",
      "6472                 xxxxx   xxxxx                 36.1                 6.93   \n",
      "7818   gdhg7u8whui 784gryb    20.2                 19.6  gdhg7u8whui 784gryb   \n",
      "12894  gdhg7u8whui 784gryb    20.2                 14.1                19.69   \n",
      "1948                   NaN    21.2                 17.1                14.59   \n",
      "...                    ...     ...                  ...                  ...   \n",
      "2210                  2.18    18.7                  NaN     88876599956788.0   \n",
      "6100                  4.49    18.5                 23.9                 9.62   \n",
      "1480                 21.89    21.2                 17.4                 16.9   \n",
      "2874                  1.38    18.6                 33.0                 8.05   \n",
      "9717                  4.05    16.6  gdhg7u8whui 784gryb                14.69   \n",
      "\n",
      "                     nbgde                 chas              ID  \\\n",
      "90                    3.16                  1.0             284   \n",
      "6472                  6.93                  0.0             305   \n",
      "7818   gdhg7u8whui 784gryb                  0.0             472   \n",
      "12894                19.69                  0.0             432   \n",
      "1948                 14.59                  0.0             138   \n",
      "...                    ...                  ...             ...   \n",
      "2210      88876599956788.0                  0.0               5   \n",
      "6100                  9.62                  0.0              85   \n",
      "1480                  16.9                  0.0             137   \n",
      "2874                  8.05                  0.0  88876599956788   \n",
      "9717                 14.69  gdhg7u8whui 784gryb             173   \n",
      "\n",
      "                      crim                  dis               tax  \\\n",
      "90                 0.01501               5885.0             198.0   \n",
      "6472               0.05515               4022.0             222.0   \n",
      "7818   gdhg7u8whui 784gryb  gdhg7u8whui 784gryb             666.0   \n",
      "12894  gdhg7u8whui 784gryb               2.0882             666.0   \n",
      "1948               0.35233               1.8498             437.0   \n",
      "...                    ...                  ...               ...   \n",
      "2210               0.06905               6.0622             222.0   \n",
      "6100               0.05059               4.7794             247.0   \n",
      "1480               0.32264               1.9669             437.0   \n",
      "2874               0.01951               9.2229  88876599956788.0   \n",
      "9717               0.13914  gdhg7u8whui 784gryb             296.0   \n",
      "\n",
      "                        rm                  age     nox  \n",
      "90                  7923.0                 24.8   401.0  \n",
      "6472                7236.0                 41.1   xxxxx  \n",
      "7818                6229.0                 90.7   532.0  \n",
      "12894  gdhg7u8whui 784gryb  gdhg7u8whui 784gryb   584.0  \n",
      "1948                   NaN                 98.4   624.0  \n",
      "...                    ...                  ...     ...  \n",
      "2210                7147.0                 54.2   458.0  \n",
      "6100                6389.0                 48.0   449.0  \n",
      "1480                5942.0                 93.5   624.0  \n",
      "2874                7104.0                 59.5  0.4161  \n",
      "9717                5572.0                 88.5    0.51  \n",
      "\n",
      "[9408 rows x 17 columns]\n",
      "       index    zn              black                rad              indus  \\\n",
      "11405     57   NaN              396.9                3.0               4.49   \n",
      "1924     274   0.0               7.68               24.0               18.1   \n",
      "8785     381   0.0             314.64               24.0               18.1   \n",
      "4373     409   0.0             262.76                4.0              21.89   \n",
      "1457      33  21.0  -26543765432345.0                4.0  -26543765432345.0   \n",
      "...      ...   ...                ...                ...                ...   \n",
      "6019     403   0.0             240.52               24.0               18.1   \n",
      "6907     211   0.0              390.7                4.0                9.9   \n",
      "7152      21   0.0                NaN                5.0                NaN   \n",
      "3219     349   0.0               9.32  -26543765432345.0  -26543765432345.0   \n",
      "11378     56  25.0             390.64                4.0               4.86   \n",
      "\n",
      "                 ptratio               medv  lstat  nbgde chas    ID     crim  \\\n",
      "11405               18.5                NaN   9.62   9.62  0.0  85.0  0.05059   \n",
      "1924                20.2                8.3  24.39  24.39  0.0   426  15.8603   \n",
      "8785                20.2               17.2   26.4   26.4  0.0   409  7.40389   \n",
      "4373                21.2               15.6  17.31  17.31  0.0   135  0.97617   \n",
      "1457   -26543765432345.0               23.4   8.43   8.43  0.0    54  0.04981   \n",
      "...                  ...                ...    ...    ...  ...   ...      ...   \n",
      "6019                20.2               10.8  23.79  23.79  0.0   445  12.8023   \n",
      "6907   -26543765432345.0  -26543765432345.0  18.33  18.33  0.0   317  0.31827   \n",
      "7152                19.2                NaN  10.13  10.13  NaN  39.0      NaN   \n",
      "3219                20.2                8.7  26.45  26.45  0.0   438  15.1772   \n",
      "11378               19.0               22.9   7.51   7.51  0.0    84  0.03551   \n",
      "\n",
      "          dis    tax      rm                age                nox  \n",
      "11405     NaN  247.0  6389.0               48.0              449.0  \n",
      "1924   1.9096  666.0  5896.0               95.4              679.0  \n",
      "8785   1.4547  xxxxx  5617.0               97.9              597.0  \n",
      "4373   2346.0  437.0  5757.0               98.4              624.0  \n",
      "1457   6.8147  243.0  5998.0               21.4  -26543765432345.0  \n",
      "...       ...    ...     ...                ...                ...  \n",
      "6019   1.8956  666.0  5854.0               96.6               0.74  \n",
      "6907   3.9986  304.0  5914.0               83.2              544.0  \n",
      "7152   3.8473    NaN     NaN               30.2              499.0  \n",
      "3219   1.9142  666.0  6152.0  -26543765432345.0               0.74  \n",
      "11378  5.4007  281.0  6167.0               46.7              426.0  \n",
      "\n",
      "[4032 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5gnmm4vdHJoV"
   },
   "source": [
    "# Descripcion  y Limpieza de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYzna68bHJoW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AFSKQY4Amzwv"
   },
   "source": [
    "## Identificacion de Variables\n",
    "- Variables de entrada y de salida\n",
    "- Tipo de Variables (categoricas o Numericas)\n",
    "- Tipo de datos (int, float, string, factor, boolean, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bnXkopIFHJob"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis General Univariable y Bivariable \n",
    "Analisis de cada una de las variables para lograr calidad de datos en cada columna\n",
    "- **Correccion del tipo de dato (numericas, categoricas, string) de cada columna (optimizar memoria)**\n",
    "- Deteccion de numero de datos faltantes\n",
    "- Deteccion de duplicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k5CEar_Cnw2x"
   },
   "source": [
    "## Eliminar columnas de datos Innecesarios\n",
    "\n",
    "Analizar el problema a resolver e indentificar cuales variables no brindan informacion y borrarlas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bxoNbnANoJt8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "que3vMzKnhwJ"
   },
   "source": [
    "## Remover Datos Duplicados Exactos\n",
    "\n",
    "Hacer al principio luego de cargar los datos y cada vez luego de Hacer imputaciones, eliminacion de columnas o registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UegcIxItnhwM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2LmnrQtbHJox"
   },
   "source": [
    "## Procesamiento de Datos Faltantes\n",
    "Las opciones que se pueden usar dependiendo del analisis de los datos son:\n",
    "### Borrar Filas\n",
    "- Borrar las filas que les falten todos los datos\n",
    "- Borrar Solo las filas que les falta las variables mas importantes o la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zFwqgwOhHJox"
   },
   "outputs": [],
   "source": [
    "data_raw.dropna(inplace=True)\n",
    "\n",
    "data_raw.isnull().any()\n",
    "data_not_null = data_raw.dropna()\n",
    "mean_zn = data_not_null['zn'].mean()\n",
    "print(mean_zn)\n",
    "missing = data_raw.isnull().sum()\n",
    "missing[missing>0]*100/len(data_raw)\n",
    "\n",
    "data_raw.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1S_iRK8rHJo0"
   },
   "source": [
    "### Reemplazar datos faltantes con la Media/ Moda/ Mediana (Mean/ Mode/ Median Imputation)\n",
    "De necesitarse hacer imputacion se debe verificar los outliers para no cometer errores en la imputacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kIIWI1KCHJo0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "68OZ-hJKHJo8"
   },
   "source": [
    "## Remover Datos Duplicados Exactos\n",
    "\n",
    "Hacer al principio luego de cargar los datos y cada vez luego de Hacer imputaciones, eliminacion de columnas o registros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6cCf27oSHJpB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GnkcN0goHJod"
   },
   "source": [
    "## Analisis Univariable\n",
    "\n",
    "Estadistico Descriptico y Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LEvH4-LGHJod"
   },
   "source": [
    "### Variables Numericas\n",
    "\n",
    "Tendencia Central  | Medida de Dispersión  |  Visualizacion\n",
    " :---: | :---: | :---:\n",
    "Media   | Rango      |  Histogramas\n",
    "Mediana | Cuartiles  |  Boxplots\n",
    "Moda    | Rango inter cuartil (IQR)|  \n",
    "Minimo  | Varianza   |  \n",
    "Maximo  | Desviacion Estandard | \n",
    "   .    | Skewness   |  \n",
    " .      | Kurtosis   |  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDTBsGi0HJoe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mXQHmtMbHJoh"
   },
   "source": [
    "### Variables Categoricas\n",
    "- Numero de elementos por categoria\n",
    "- Porcentaje de elementos por categoria\n",
    "- Graficos de barras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPY0sHqNHJoi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmf_f9TOHJok"
   },
   "source": [
    "## Analisis Bivariable\n",
    "Estadistico Descriptico y Analisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3aVUkwJVHJom"
   },
   "source": [
    "### Numericas vs Numericas\n",
    "- Scatter Plot\n",
    "- Heatmap\n",
    "- Correlacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "067r3JdGHJon"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9SfZHh6oHJor"
   },
   "source": [
    "### Categoricas vs Categoricas\n",
    "\n",
    "- Two-way table\n",
    "- Graficas de Barras apiladas\n",
    "- Chi-Square Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T544jyPsHJos"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oQKXaEcqHJou"
   },
   "source": [
    "### Categoricas vs Numericas\n",
    "- Z-Test/ T-Test\n",
    "- ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F8coJJA6HJov"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r2X6dK04HJpD"
   },
   "source": [
    "## Procesamiento de Outliers\n",
    "### Deteccion de Outliers (Univariables y Bi variables)\n",
    "- Boxplots\n",
    "- Scatter Plots\n",
    "- Histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bc5mYM_qHJpE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aiDgzB32HJpI"
   },
   "source": [
    "### Remover Outliers\n",
    "las opciones son:\n",
    "- Borrar los datos atipicos (outliers) \n",
    "- Transformar la variable (Ej: escalar, cambiar a esccala Log o a Escala lineal)\n",
    "- Reemplazar los outliers conla Media/ Moda/ Mediana (Mean/ Mode/ Median Imputation)\n",
    "- Reemplazar valores con modelo predictivo\n",
    "- Separarlos y analizarlos aparte (si son muchos outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DsDqeIPbHJpI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r2X6dK04HJpD"
   },
   "source": [
    "## Procesamiento de Outliers\n",
    "### Deteccion de Outliers (Univariables y Bi variables)\n",
    "- Boxplots\n",
    "- Scatter Plots\n",
    "- Histogramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bc5mYM_qHJpE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aiDgzB32HJpI"
   },
   "source": [
    "### Remover Outliers\n",
    "las opciones son:\n",
    "- Borrar los datos atipicos (outliers) \n",
    "- Transformar la variable (Ej: escalar, cambiar a esccala Log o a Escala lineal)\n",
    "- Reemplazar los outliers conla Media/ Moda/ Mediana (Mean/ Mode/ Median Imputation)\n",
    "- Reemplazar valores con modelo predictivo\n",
    "- Separarlos y analizarlos aparte (si son muchos outliers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DsDqeIPbHJpI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s4Fn2YIvHJpL"
   },
   "source": [
    "## Feature Engineering \n",
    "### Transformacion de Variables\n",
    "**Se usa cuando es necesario:**\n",
    "- Cambiar la escala las variables (Normalizar, escalamiento, etc), esto no cambia la forma de la distribucion de los datos\n",
    "- Cambiar relaciones No ineales en Lineales (Ej: cambiar la escala Logaritmica a lineal)\n",
    "- Usar una la distribución simétrica en vez de una distribución sesgada o asimetrica, Para una la distribución sesgada a la derecha, tomamos la raíz cuadrada / cúbica o el logaritmo de la variable, y para la desviación a la izquierda, tomamos el cuadrado / cubo o exponencial de las variables.\n",
    "- Cambair variables continuas a categoricas\n",
    "\n",
    "Algunas transformaciones son:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "he4lxsEUHJpM"
   },
   "source": [
    "#### Normalizacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7giKrRY8HJpM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h0FKIrJHHJpO"
   },
   "source": [
    "#### Escalamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hzGcwGaWHJpP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYPdefrhHJpS"
   },
   "source": [
    "#### Logaritmica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wU-lW1AQHJpS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUundEM6HJpT"
   },
   "source": [
    "#### raíz cuadrada / cúbica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5woteVvBHJpU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2GNrgJzHHJpW"
   },
   "source": [
    "#### Binning , Cambios de Numericas a Categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cS5y1OPSHJpW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6PpnSEDHJpY"
   },
   "source": [
    "## Analisis Univariable y Bivariable Final\n",
    "Luego de Realizar:\n",
    "- Tratamiento de datos Nulos\n",
    "- Tratamiento de outliers\n",
    "- Transformacion de Variables\n",
    "\n",
    "Es necesario realizar nuevamente analisis univarible y bivariable para identificar como cambiaron nuestros datos y para verificar si estan listos para usarse para crear un modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uRwep7LjHJpZ"
   },
   "source": [
    "### Creacion de Variables\n",
    "pueden ser:\n",
    "#### Crear Variables derivadas de Otras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ywBVDG8vHJpZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JCcM4XFbHJpd"
   },
   "source": [
    "#### Crear Variables de Categorico a Numerico\n",
    "Puede ser\n",
    "- Definir un numero a cada categoria\n",
    "- One hot encoder (dummy columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ubILpEdWHJpi"
   },
   "source": [
    "## Reduccion de Dimensionalidad y Seleccion de Variables (PCA)\n",
    "\n",
    "De ser necesario si tiene muchas variables o sospecha que aun tiene variables que no aportan mucho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2JIcRk-HJpi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oEu3sW98HJpk"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lw3hG0rCHJpl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELAMIENTO DE LOS DATOS (MACHINE LEARNING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validacion y Evaluacion Cruzada (k-fold Cross Validation)\n",
    "\n",
    "Se hace seleccion de los mejores modelos usando el Training Set y k-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizacion de Hiper parametros (Hyper Parameter optimization)\n",
    "\n",
    "Se seleccionan solo los mejores modelos para realizar el ajuste de hiperparametros, ya que tiene una carga computacional alta.\n",
    "\n",
    "Al final se obtienen los parametros del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluacion final del modelo con el Test set\n",
    "\n",
    "Tomar los parametros obtenidos en el paso anterior, se crea el modelo con esos pararmetros y se entrena el modelo con todos los datos del **Train -set**\n",
    "\n",
    "Finalmente se realiza la evaluacion (segun su problema si es de regresion o de clasificacion) usando el **Test - set** para definir si el modelo obtenido esta bien. Compare los resultados con el **Train -set** vs los resultados con el **Test - set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementacion del Modelo (Deploying)\n",
    "Con el análisis básico y el ajuste hecho, comienza el trabajo real (ingeniería).\n",
    "\n",
    "El último paso para poner en produccion el modelo de prediccion sera:\n",
    "1. Entrenarlo en todo el conjunto de datos nuevamente, para hacer un uso completo de todos los datos disponibles. \n",
    "2. Usar los mejores parámetros encontrados mediante la validación cruzada, por supuesto. Esto es muy similar a lo que hicimos al principio, pero esta vez teniendo una idea de su comportamiento y estabilidad. La evaluación se realizó con honestidad, en divisiones distintas de entrenamiento / prueba.\n",
    "\n",
    "El predictor final se puede serializar y grabar en el disco, de modo que la próxima vez que lo usemos, podemos omitir todo el entrenamiento y usar el modelo capacitado directamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pickle # Esta es una libreria de serializacion nativa de python, puede tener problemas de seguridad\n",
    "from joblib import dump # libreria de serializacion\n",
    "\n",
    "# garbar el modelo en un archivo\n",
    "#dump(Modelo_final, 'Nombre_Archivo_Modelo.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comunicacion de Resultados (Data Story Telling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ayudas Y Referencias\n",
    "\n",
    "- https://medium.com/@joserzapata/paso-a-paso-en-un-proyecto-machine-learning-bcdd0939d387\n",
    "- [Proyecto de Principio a Final sobre readmision de pacientes con Diabetes](https://github.com/JoseRZapata/Readmission-ML-Project)\n",
    "\n",
    "- [a-complete-machine-learning-walk-through-in-python-part-one](https://towardsdatascience.com/a-complete-machine-learning-walk-through-in-python-part-one-c62152f39420)\n",
    "\n",
    "\n",
    "- [a-starter-pack-to-exploratory-data-analysis-with-python-pandas-seaborn-and-scikit-learn](https://towardsdatascience.com/a-starter-pack-to-exploratory-data-analysis-with-python-pandas-seaborn-and-scikit-learn-a77889485baf#249d)\n",
    "\n",
    "- [a-data-science-for-good-machine-learning-project-walk-through-in-python-part-one](https://towardsdatascience.com/a-data-science-for-good-machine-learning-project-walk-through-in-python-part-one-1977dd701dbc)\n",
    "\n",
    "- [Ejemplos de Kaggle](https://www.kaggle.com/kernels?sortBy=hotness&group=everyone&pageSize=20&language=Python&kernelType=Notebook)\n",
    "\n",
    "- [END to END ML from data colletion to deployment](https://medium.com/datadriveninvestor/end-to-end-machine-learning-from-data-collection-to-deployment-ce74f51ca203)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docente: [Jose R. Zapata](https://joserzapata.github.io)\n",
    "- https://joserzapata.github.io\n",
    "- https://twitter.com/joserzapata\n",
    "- https://www.linkedin.com/in/jose-ricardo-zapata-gonzalez/   "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "mXQHmtMbHJoh",
    "3aVUkwJVHJom",
    "9SfZHh6oHJor",
    "1S_iRK8rHJo0",
    "Ey5Lk8evHJo3",
    "0Y0UV-GVHJo6",
    "he4lxsEUHJpM",
    "h0FKIrJHHJpO",
    "jYPdefrhHJpS",
    "zUundEM6HJpT",
    "2GNrgJzHHJpW",
    "uRwep7LjHJpZ",
    "JCcM4XFbHJpd"
   ],
   "name": "Trabajo_Preparacion_Datos_JoseR_Zapata.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "es",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "es",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Contenido",
   "title_sidebar": "Contenido",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "3613889f8975fa3e145fc20b32b690577f6793d069cb05b03eb21a79c30638cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
